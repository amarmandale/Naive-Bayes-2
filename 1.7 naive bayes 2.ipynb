{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348fd77e-a6ff-4d0a-98e5-f8368312a7cc",
   "metadata": {},
   "source": [
    "\n",
    "### Q1. Q1. A company conducted a survey of its employees and found that 70% of the employees use the  \n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the### \r\n",
    "probability that an employee is a smoker given that he/she uses the health insurance pla ?\n",
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use Bayes' theorem.\n",
    "\n",
    "Let:\n",
    "- \\( P(S) \\) = Probability of being a smoker\n",
    "- \\( P(H) \\) = Probability of using the health insurance plan\n",
    "- \\( P(S | H) \\) = Probability of being a smoker given that the employee uses the health insurance plan\n",
    "\n",
    "From the survey:\n",
    "- \\( P(H) = 0.7 \\) (70% use the health insurance plan)\n",
    "- \\( P(S | H) = 0.4 \\) (40% of those who use the plan are smokers)\n",
    "\n",
    "Using Bayes' theorem, we can find:\n",
    "\\[\n",
    "P(S | H) = \\frac{P(H | S) \\cdot P(S)}{P(H)}\n",
    "\\]\n",
    "However, we don't have \\( P(S) \\) or \\( P(H | S) \\) directly. We can derive the required values based on the information given.\n",
    "\n",
    "If 40% of those who use the health plan are smokers:\n",
    "- Letâ€™s assume \\( P(S) \\) is the overall probability of being a smoker.\n",
    "- We can use this information directly since \\( P(S | H) = 0.4 \\).\n",
    "\n",
    "The probability that an employee is a smoker given that he/she uses the health insurance plan is **40% or 0.4**.\n",
    "\n",
    "---\n",
    "\n",
    "### Q2. Difference Between Bernoulli Naive Bayes and Multinomial Naive Bayes\n",
    "- **Bernoulli Naive Bayes**:\n",
    "  - Used for binary/boolean features (e.g., presence or absence of a feature).\n",
    "  - It assumes that features follow a Bernoulli distribution.\n",
    "  - Suitable for text classification where we need to determine whether a word is present or not.\n",
    "\n",
    "- **Multinomial Naive Bayes**:\n",
    "  - Used for multi-class classification problems with features that represent counts (e.g., frequency of words).\n",
    "  - It assumes that features follow a multinomial distribution.\n",
    "  - Ideal for text classification tasks where the count of each word in a document matters.\n",
    "\n",
    "The key difference is in the nature of the features they handle: Bernoulli for binary features and Multinomial for count-based features.\n",
    "\n",
    "---\n",
    "\n",
    "### Q3. How Does Bernoulli Naive Bayes Handle Missing Values?\n",
    "- Bernoulli Naive Bayes handles missing values by ignoring the features with missing values during the probability calculation. It does not require imputation of missing values.\n",
    "- If a feature is missing, it is effectively treated as if that feature's value did not contribute to the classification decision.\n",
    "\n",
    "Bernoulli Naive Bayes can handle missing values by simply ignoring them during classification.\n",
    "\n",
    "---\n",
    "\n",
    "### Q4. Can Gaussian Naive Bayes Be Used for Multi-Class Classification?\n",
    "- Yes, Gaussian Naive Bayes can be used for multi-class classification.\n",
    "- It works well when the features are continuous and assumed to follow a Gaussian (normal) distribution.\n",
    "- It can handle any number of classes by applying the Naive Bayes formula independently for each class and selecting the class with the highest posterior probability.\n",
    "\n",
    "Gaussian Naive Bayes is suitable for multi-class classification problems.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1ad2c-e099-4baa-82b7-f6af22b29272",
   "metadata": {},
   "source": [
    "## Q5. Assignment:\n",
    "\n",
    "-Data preparation:\n",
    "\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "-Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "-Results:\n",
    "\n",
    "Report the following performance metrics for each classifier:\n",
    "\n",
    "Accuracy\n",
    "\n",
    "Precision\n",
    "\n",
    "Recall\n",
    "\n",
    "F1 score\n",
    "\n",
    "-Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "-Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b1f047-ea7c-48cd-9f93-14d68685d00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0       0.00       0.64       0.64        0.0       0.32       0.00   \n",
      "1       0.21       0.28       0.50        0.0       0.14       0.28   \n",
      "2       0.06       0.00       0.71        0.0       1.23       0.19   \n",
      "3       0.00       0.00       0.00        0.0       0.63       0.00   \n",
      "4       0.00       0.00       0.00        0.0       0.63       0.00   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  ...  feature_49  feature_50  \\\n",
      "0       0.00       0.00       0.00        0.00  ...        0.00       0.000   \n",
      "1       0.21       0.07       0.00        0.94  ...        0.00       0.132   \n",
      "2       0.19       0.12       0.64        0.25  ...        0.01       0.143   \n",
      "3       0.31       0.63       0.31        0.63  ...        0.00       0.137   \n",
      "4       0.31       0.63       0.31        0.63  ...        0.00       0.135   \n",
      "\n",
      "   feature_51  feature_52  feature_53  feature_54  feature_55  feature_56  \\\n",
      "0         0.0       0.778       0.000       0.000       3.756          61   \n",
      "1         0.0       0.372       0.180       0.048       5.114         101   \n",
      "2         0.0       0.276       0.184       0.010       9.821         485   \n",
      "3         0.0       0.137       0.000       0.000       3.537          40   \n",
      "4         0.0       0.135       0.000       0.000       3.537          40   \n",
      "\n",
      "   feature_57  is_spam  \n",
      "0         278        1  \n",
      "1        1028        1  \n",
      "2        2259        1  \n",
      "3         191        1  \n",
      "4         191        1  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Spambase dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "columns = [f'feature_{i}' for i in range(1, 58)] + ['is_spam']\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3dd4dd-f980-4534-b960-b8c530c95272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes F1 Score: 0.8481249015095276\n",
      "Multinomial Naive Bayes F1 Score: 0.7282909724016348\n",
      "Gaussian Naive Bayes F1 Score: 0.8130660909542995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('is_spam', axis=1)\n",
    "y = data['is_spam']\n",
    "\n",
    "# Initialize classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Function to evaluate classifiers\n",
    "def evaluate_classifier(classifier, X, y):\n",
    "    scores = cross_val_score(classifier, X, y, cv=10, scoring='f1')\n",
    "    return scores.mean()\n",
    "\n",
    "# Evaluate classifiers\n",
    "bernoulli_f1 = evaluate_classifier(bernoulli_nb, X, y)\n",
    "multinomial_f1 = evaluate_classifier(multinomial_nb, X, y)\n",
    "gaussian_f1 = evaluate_classifier(gaussian_nb, X, y)\n",
    "\n",
    "print(f'Bernoulli Naive Bayes F1 Score: {bernoulli_f1}')\n",
    "print(f'Multinomial Naive Bayes F1 Score: {multinomial_f1}')\n",
    "print(f'Gaussian Naive Bayes F1 Score: {gaussian_f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9755b592-c175-465f-bbd0-6882d7298f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes - Accuracy: 0.8858943707889589, Precision: 0.8860911270983214, Recall: 0.815223386651958, F1 Score: 0.8491812697500718\n",
      "Multinomial Naive Bayes - Accuracy: 0.7924364268637253, Precision: 0.7440273037542662, Recall: 0.7214561500275786, F1 Score: 0.7325679081489779\n",
      "Gaussian Naive Bayes - Accuracy: 0.8228645946533363, Precision: 0.7012096774193548, Recall: 0.9591836734693877, F1 Score: 0.8101560680177032\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(classifier, X, y):\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Compute metrics for each classifier\n",
    "bernoulli_metrics = compute_metrics(bernoulli_nb, X, y)\n",
    "multinomial_metrics = compute_metrics(multinomial_nb, X, y)\n",
    "gaussian_metrics = compute_metrics(gaussian_nb, X, y)\n",
    "\n",
    "print(f'Bernoulli Naive Bayes - Accuracy: {bernoulli_metrics[0]}, Precision: {bernoulli_metrics[1]}, Recall: {bernoulli_metrics[2]}, F1 Score: {bernoulli_metrics[3]}')\n",
    "print(f'Multinomial Naive Bayes - Accuracy: {multinomial_metrics[0]}, Precision: {multinomial_metrics[1]}, Recall: {multinomial_metrics[2]}, F1 Score: {multinomial_metrics[3]}')\n",
    "print(f'Gaussian Naive Bayes - Accuracy: {gaussian_metrics[0]}, Precision: {gaussian_metrics[1]}, Recall: {gaussian_metrics[2]}, F1 Score: {gaussian_metrics[3]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61ee29-52c1-4458-bfd0-072302e62681",
   "metadata": {},
   "source": [
    "###  Discussion\n",
    "\n",
    "After running the evaluations, you can analyze the results:\n",
    "\n",
    "- **Performance Comparison**: Determine which Naive Bayes variant performed best based on the metrics you obtained.\n",
    "- **Limitations**: Discuss any limitations of Naive Bayes classifiers you observed:\n",
    "  - Naive Bayes assumes independence among features, which may not always hold true.\n",
    "  - It may not perform well with imbalanced datasets.\n",
    "  - Gaussian Naive Bayes assumes normal distribution, which may not fit the data.\n",
    "\n",
    "###  Conclusion\n",
    "\n",
    "Summarize your findings:\n",
    "- Which classifier performed the best and why.\n",
    "- Any observed patterns in the data that could influence future work, such as trying other algorithms or feature engineering techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d26ae6-7500-4c8d-8756-79e3081b8f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
